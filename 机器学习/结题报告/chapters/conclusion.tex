\section{结论}

卷积神经网络(CNN)和Vision Transformer(ViT)是两种截然不同的模型，前者的主要操作是卷积，而后者的主要操作是自注意力机制。本章节将通过理论推导进行分析，比较CNN和ViT的差异和可能的内在原因。之后通过对全局和局部特征、降维可视化、模型性能和泛化性能的比较，进一步分析和比较了CNN和ViT的差异和造成差异的内在原因。通过实验，本文得出了以下主要结论：

\begin{enumerate}
    \item 受到卷积结构的限制，CNN倾向于关注固定形状的特征区域，且需要从浅到深逐步提取特征，这与人类大脑的工作机制更为接近。而ViT倾向于学习更自由的特征区域，能够在浅层就学到高级语义信息。
    \item CNN对于形状、纹理、尺寸、视角等因素具备更强的鲁棒性，同时对图像变换具备更强大不变性。
    \item CNN具备更强大的跨数据集迁移学习能力，而ViT在对抗性图像上表现更好。
\end{enumerate}

本文的工作揭开了CNN和ViT的内在差异，为未来的工作提供了新的启发。本文认为虽然ViT在图像分类任务上取得了很好的效果，但是CNN可能会以一种工具的形式继续存在，例如DeTR等模型的结构中也包含了CNN的部分结构，此外CNN也可以用来学习位置编码等信息。因此，未来的工作可以通过结合CNN和ViT的优势，设计更加强大的模型，提高模型的泛化能力和鲁棒性。
