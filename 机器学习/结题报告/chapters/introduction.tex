\section{介绍}

% 介绍背景
在计算机视觉领域，卷积神经网络(CNN)\cite{9451544}和Vision Transformer(ViT)\cite{dosovitskiy2021image}是两种截然不同的模型，前者的主要操作是卷积，而后者的主要操作是自注意力机制。CNN是一种传统的基于卷积操作的神经网络，在传统的计算机视觉任务如图像分类、目标检测等任务中取得了巨大成功。而ViT是一种新兴的神经网络模型，它通过自注意力机制来捕捉序列中的长距离依赖关系，取得了超越CNN的效果。

% 介绍CNN的发展历史
卷积神经网络(CNN)是一种传统的基于卷积操作的神经网络，在图像分类、目标检测等任务中取得了巨大成功。2012年，AlexNet\cite{krizhevsky2012imagenet}首次将卷积神经网络引入图像分类任务，取得了ImageNet\cite{5206848}比赛的冠军。之后，VGG\cite{simonyan2015deep}、GoogLeNet\cite{szegedy2015going}、ResNet\cite{he2016deep}等模型相继提出，不断提高了图像分类任务的性能。这些模型通过卷积、池化、Batch Normalization、激活函数等操作，逐渐提取出输入数据的高层次特征。其中，卷积操作是CNN的核心操作，卷积操作的本质是一种特殊的线性变换，它通过卷积核与输入数据的点乘操作，将输入数据的局部特征提取出来。卷积操作的局部性质使得CNN能够有效地提取空间特征，因此CNN在图像处理领域取得了巨大的成功。

% 介绍NLP中的transformer以及ViT的发展历史
Transformer\cite{vaswani2017attention}是一种在自然语言处理领域取得巨大成功的模型，通过自注意力机制来捕捉序列中的长距离依赖关系。在自然语言处理领域，基于Transformer的两种经典架构是BERT\cite{devlin-etal-2019-bert}和GPT\cite{radford2018improving}，两者分别通过掩码学习和自回归学习来学习文本的表示。这类模型通过自注意力、Layer Normalization、激活函数等操作，逐渐提取出输入数据的高层次特征，取得了超越传统RNN模型的效果。受到自然语言处理领域的启发，Vision Transformer(ViT)将图像分割成若干个图块并组成序列，然后按照Transformer的方式对序列进行处理。ViT在图像分类、目标检测等任务中取得了超越CNN的效果，表明自注意力机制在计算机视觉领域的有效性。

% 介绍本文的目标，引出问题，两者存在哪些差异
然而，CNN和ViT是两种截然不同的模型，它们的结构、特征表示、泛化能力等方面存在很大的差异。CNN是一种基于卷积操作的神经网络，它通过卷积核与输入数据的点乘操作，提取输入数据的局部特征。而ViT是一种基于自注意力机制的神经网络，它可以对序列中任意两个元素之间的关系进行建模。这两种模型的差异可能导致它们在不同的任务上表现出不同的优劣势。因此，本文的目标是比较CNN和ViT的差异，揭示两者的优劣势，探讨两者的内在原因。本文着重关注如下问题：

\textit{CNN和ViT存在哪些差异？哪些原因导致了两者的差异？}

% 介绍本文的方法，如何比较两者的差异
考虑到两者的差异，本文将从全局和局部特征、降维可视化、模型性能和泛化能力的角度对CNN和ViT进行比较。通过这些方法，本文将详细对两者关注的特征表示、模型性能和通用性、适用任务等角度进行比较，揭示两者的优劣势。

% 介绍本文的结果，两者的差异、优劣势
实验结果表明，CNN和ViT在不同的任务上表现出不同的优劣势。受到归纳偏置的作用，CNN倾向于学习更规则的区域，其形状类似于卷积核的感受野。而ViT则倾向于学习更不规则的区域，呈现成片的形状。这种差异使得CNN更适用于学习局部特征，而ViT更适用于学习全局特征，并更为偏向于细节特征，同时也更容易过拟合到噪声上。此外，ViT的较低层就学习到高级语义特征，而CNN需要逐层汇总才能学习到高级语义特征。通过降维可视化，本文发现CNN在细粒度数据集上具有更好的效果。

为了探究CNN和ViT对哪些因素敏感，本文选择了不同的数据集和任务进行分析。本文发现，CNN在纹理、形状等细节特征上相比ViT具有更好的性能，同时具备更好的变换不变性。此外，CNN在跨数据集泛化能力上更优于ViT，这可能是因为归纳偏置的假设对于所有图像来说都是通用的。

% 介绍本文的贡献
总的来说，本文的主要贡献在于：

\begin{enumerate}
  \item 本文揭示了CNN和ViT存在本质上的差异，并从理论上分析了两者的区别和可能的原因。
  \item 本文提出了基于特征、降维可视化、性能和泛化能力等方面的比较方法，详细比较了CNN和ViT的优劣势，以及具体的影响因素。
  \item 虽然ViT如今在图像分类、目标检测等任务中取得了很好的效果，但本文发现CNN在各种任务上仍然具有优势，同时具备更好的细粒度、纹理形状等特征的提取能力和跨数据集的泛化能力，这对于未来的研究具有指导意义。
\end{enumerate}